{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36732caf-6f52-4141-ac05-62f824486e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import joblib\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB,BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f534999f-929e-4913-9b53-88660764f817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"Email Spam Detection.csv\",encoding='latin-1')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5fd8e3a0-2c36-4c06-8842-9f6969f24604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>will ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>pity, * was in mood for that. so...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>the guy did some bitching but i acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>rofl. its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5169 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2\n",
       "0      ham  go until jurong point, crazy.. available only ...\n",
       "1      ham                      ok lar... joking wif u oni...\n",
       "2     spam  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3      ham  u dun say so early hor... u c already then say...\n",
       "4      ham  nah i don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  this is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              will ì_ b going to esplanade fr home?\n",
       "5569   ham  pity, * was in mood for that. so...any other s...\n",
       "5570   ham  the guy did some bitching but i acted like i'd...\n",
       "5571   ham                         rofl. its true to its name\n",
       "\n",
       "[5169 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Cleaning \n",
    "data.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)\n",
    "data.drop_duplicates(inplace=True)\n",
    "data['v2']=data['v2'].apply(lambda x:x.lower())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed65bb6b-9903-448a-84a4-30f36e3620e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think goes usf lives around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>nd time tried contact u u pound prize claim ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>will ì_ b going to esplanade fr home?</td>\n",
       "      <td>b going esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>pity, * was in mood for that. so...any other s...</td>\n",
       "      <td>pity mood suggestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>the guy did some bitching but i acted like i'd...</td>\n",
       "      <td>guy bitching acted like interested buying some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>rofl. its true to its name</td>\n",
       "      <td>rofl true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5169 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2  \\\n",
       "0      ham  go until jurong point, crazy.. available only ...   \n",
       "1      ham                      ok lar... joking wif u oni...   \n",
       "2     spam  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3      ham  u dun say so early hor... u c already then say...   \n",
       "4      ham  nah i don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567  spam  this is the 2nd time we have tried 2 contact u...   \n",
       "5568   ham              will ì_ b going to esplanade fr home?   \n",
       "5569   ham  pity, * was in mood for that. so...any other s...   \n",
       "5570   ham  the guy did some bitching but i acted like i'd...   \n",
       "5571   ham                         rofl. its true to its name   \n",
       "\n",
       "                                         tokenized_text  \n",
       "0     go jurong point crazy available bugis n great ...  \n",
       "1                               ok lar joking wif u oni  \n",
       "2     free entry wkly comp win fa cup final tkts st ...  \n",
       "3                   u dun say early hor u c already say  \n",
       "4                nah think goes usf lives around though  \n",
       "...                                                 ...  \n",
       "5567  nd time tried contact u u pound prize claim ea...  \n",
       "5568                          b going esplanade fr home  \n",
       "5569                              pity mood suggestions  \n",
       "5570  guy bitching acted like interested buying some...  \n",
       "5571                                     rofl true name  \n",
       "\n",
       "[5169 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization\n",
    "def preprocess(text):\n",
    "    text=re.sub(r\"[^a-zA-Z]\",\" \",text)\n",
    "    words=word_tokenize(text)\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    words=[word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "data['tokenized_text']=data['v2'].apply(preprocess)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3e5cf20c-75ad-485e-b229-181439b515a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Vectorization\n",
    "tfidf_vectorizer=TfidfVectorizer()\n",
    "X=tfidf_vectorizer.fit_transform(data['tokenized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2d999e97-ec5b-47c2-aa57-ee983948a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data splitting\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,data['v1'],test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cac78e8c-0b71-4c0a-bd34-8a4d592c7dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training a Multinomial Naive Bayes Model \n",
    "multiNB=MultinomialNB()\n",
    "multiNB.fit(X_train,Y_train)\n",
    "multiNBPre=multiNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c638f2a5-ad61-4768-80d7-2970c7b2247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training a Bernoulli Naive Bayes Model \n",
    "BerNB=BernoulliNB()\n",
    "BerNB.fit(X_train,Y_train)\n",
    "BerNBPre=BerNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b3559d23-83e4-4892-9f2d-52a3b9ee7e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training a Gaussian Naive Bayes Model \n",
    "gaussNB=GaussianNB()\n",
    "gaussNB.fit(X_train.toarray(),Y_train)\n",
    "gaussNBPre=gaussNB.predict(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "940dcc37-b829-4a85-8c98-db6403822b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Multinomial model 0.9690522243713733\n",
      "From Bernoulli model 0.9709864603481625\n",
      "From Gaussian model 0.8733075435203095\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the accuracy on the test set for the models\n",
    "print(\"From Multinomial model\",accuracy_score(Y_test,multiNBPre))\n",
    "print(\"From Bernoulli model\",accuracy_score(Y_test,BerNBPre))\n",
    "print(\"From Gaussian model\",accuracy_score(Y_test,gaussNBPre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "790b2f9e-dc50-4370-b5e4-8f08b0d03833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to the Accuracy Score the best model for email spam detection is Bernoulli Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5621f219-8a8a-4496-b9ec-a9d47ab933eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_joblib.pkl']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the best model\n",
    "joblib.dump(BerNB,'model_joblib.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5f2584a8-508a-428e-8197-d93268558d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the TF-IDF vectorizer using pickle\n",
    "with open('tfidf_vectorizer.pkl','wb') as file:\n",
    "    pickle.dump(tfidf_vectorizer,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
